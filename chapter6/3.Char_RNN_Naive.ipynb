{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import unidecode\n",
    "import string\n",
    "import random\n",
    "import time, math\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(\"./data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-02-23 09:22:35--  https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/tinyshakespeare/input.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
      "접속 raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... 접속됨.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1115394 (1.1M) [text/plain]\n",
      "Saving to: ‘./data/input.txt’\n",
      "\n",
      "input.txt           100%[===================>]   1.06M  1.91MB/s    in 0.6s    \n",
      "\n",
      "2021-02-23 09:22:36 (1.91 MB/s) - ‘./data/input.txt’ saved [1115394/1115394]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/tinyshakespeare/input.txt -P ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~ \\t\\n\\r\\x0b\\x0c'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#출력 가능한 모든 문자 불러옴\n",
    "all_characters = string.printable\n",
    "all_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_characters = len(all_characters)\n",
    "n_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115394"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = unidecode.unidecode(open('./data/input.txt').read())\n",
    "file_len = len(file)\n",
    "file_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_every = 100\n",
    "plot_every = 10\n",
    "\n",
    "chunk_len = 200\n",
    "\n",
    "num_epochs = 2000\n",
    "hidden_size = 100\n",
    "batch_size = 1\n",
    "num_layers = 1\n",
    "embedding_size = 70\n",
    "lr = 0.002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#파일의 일부분을 랜덤하게 불러오는 함수\n",
    "def random_chunk():\n",
    "    start_index = random.randint(0, file_len - chunk_len)\n",
    "    end_index = start_index + chunk_len + 1\n",
    "    return file[start_index:end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#문자열을 인덱스 배열로 바꿔주는 함수\n",
    "def char_tensor(string):\n",
    "    tensor = torch.zeros(len(string)).long()\n",
    "    for i in range(len(string)):\n",
    "        tensor[i] = all_characters.index(string[i])\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random text chunk를 불러와서 입력과 목표값을 바꿔주는 함수\n",
    "def random_training_set():\n",
    "    chunk = random_chunk()\n",
    "    inp = char_tensor(chunk[:-1])\n",
    "    tar = char_tensor(chunk[1:])\n",
    "    return inp, tar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.encoder = nn.Embedding(self.input_size, self.embedding_size)\n",
    "        self.rnn = nn.RNN(self.embedding_size, self.hidden_size, self.num_layers)\n",
    "        self.decoder = nn.Linear(self.hidden_size, self.output_size)\n",
    "        \n",
    "    def forward(self, inp, hidden):\n",
    "        out = self.encoder(inp.view(1, -1))\n",
    "        out, hidden = self.rnn(out, hidden)\n",
    "        out = self.decoder(out.view(batch_size, -1))\n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(input_size = n_characters, \n",
    "            embedding_size = embedding_size,\n",
    "            hidden_size = hidden_size,\n",
    "            output_size = n_characters, \n",
    "            num_layers = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#임의의 문자로 시작하는 길이 200짜리 모방글 생성\n",
    "def test():\n",
    "    start_str = \"b\"\n",
    "    inp = char_tensor(start_str)\n",
    "    hidden = model.init_hidden()\n",
    "    \n",
    "    print(start_str, end=\"\")\n",
    "    \n",
    "    for i in range(200):\n",
    "        output, hidden = model(inp, hidden)\n",
    "        output_dist = output.data.view(-1).div(0.8).exp()\n",
    "        top_n = torch.multinomial(output_dist, 1)[0]\n",
    "        predicted_char = all_characters[top_n]\n",
    "        print(predicted_char, end=\"\")\n",
    "        inp = char_tensor(predicted_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " tensor([4.5515], grad_fn=<DivBackward0>) \n",
      "\n",
      "8[/\"\"y;`C`Lz](Kf\n",
      "->^KDzD-f~uWSni$<r;\u000b",
      ">v<ArL6BQ\"G*wmrC7\\(QRS%2O,i,3ZvGaX(18P%[ym\"Zg^\n",
      "h\\)M}RnQSohO~GrcXS&Lisj8-ks9|:ozna7}\f",
      "}w?5728Sh3V|==\"Um`)J6\u000b",
      "tPh`F{@GY$18\t`(RDOnvc,qS[*6sapI\f",
      "&%>lrB<q#-1j\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([2.6015], grad_fn=<DivBackward0>) \n",
      "\n",
      "bsyined hath med hit.\n",
      "\n",
      "EEuAty:\n",
      "Ig be hourd and nesele beeond tho here hor and he to to iel mong yeree anw rim te afl uy brart miras houte;\n",
      "IvATEN:\n",
      "Thirt fot' Nes tert ad anlillt fite mat te;s sey nont \n",
      " ====================================================================================================\n",
      "\n",
      " tensor([2.1938], grad_fn=<DivBackward0>) \n",
      "\n",
      "bror to shay go chars wale thay the bromw,\n",
      "^o any you to sur beder ond youol ast I youhs apas Po.\n",
      "\n",
      "Arsupthal' ongent ay of seare\n",
      "\n",
      "hake serol or mong me mall tnoth seafyoor wing shyor and opade renw the\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([2.1895], grad_fn=<DivBackward0>) \n",
      "\n",
      "be hey wathoulle homes yourdertand thee ave latters\n",
      "On womenbessimuss I thand kbut to hage cy,\n",
      "Wowe, my pore.\n",
      "\n",
      "BERGINEGIRHTIN:\n",
      "I do at I mach cowe ward athoufter gotse shangrime.\n",
      "\n",
      "RICEE:\n",
      "Bet beelh me h\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([2.0640], grad_fn=<DivBackward0>) \n",
      "\n",
      "berere qroes yerve?\n",
      "With nor in chill, to amto, then, and; a tith loth will speaps ansy we thoue, theren, crireck on ther\n",
      "Whysactlo nong be your it me shet be swaings, chet to he, I pe eir stals,\n",
      "Leire\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([2.2021], grad_fn=<DivBackward0>) \n",
      "\n",
      "bedent ous arsunce.\n",
      "\n",
      "GLBNIUY:\n",
      "Wall wergen heang I sis that hinchouned,\n",
      "One tay whe shat sape ande, lather\n",
      "Whas my too't heur and wist as that to sime the inist a more this the on thournester fullot you\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([2.1186], grad_fn=<DivBackward0>) \n",
      "\n",
      "beio, weemsing weather preas dinink the\n",
      "keathiln:\n",
      "Why come star'tise sir as good nockering fripile to moth in had smalaind not that sil wet sare swall knor whem were drart the the with hecrome stater w\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([2.1081], grad_fn=<DivBackward0>) \n",
      "\n",
      "bress the of the love in:\n",
      "But hen I let he the chaw a minition\n",
      "Kir come way and your thit of for himg-ing of tha your more at, I farys you lades.\n",
      "\n",
      "EDALD:\n",
      "Pord voon and youn thy more shall in mate.\n",
      "Whan\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.9613], grad_fn=<DivBackward0>) \n",
      "\n",
      "brave you hides will you your and to the nood the somer, your thim, you till mores owd and nother his the poothrent aur,\n",
      "Haps thou thy mand hear you the stransard:\n",
      "Thas you och wife the this the kert o\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.9272], grad_fn=<DivBackward0>) \n",
      "\n",
      "by!\n",
      "\n",
      "CERD:\n",
      "As the begwinds inteld?\n",
      "\n",
      "ISartech the will heme to my bour spead intorne is for that could him thy dowe in me there he, he searieg soungy-d\n",
      "well he sees wible scord the mine come in hown ort\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.9454], grad_fn=<DivBackward0>) \n",
      "\n",
      "ble good vear,\n",
      "Estrunget sither mar thyed Carelantemes.\n",
      "\n",
      "LORANGA:\n",
      "I houthanded trewcey, wore shall comy pive must, I am thou mad, and or, to thou rempard, thou llecring chapit. Nor datell a grease ey p\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.9727], grad_fn=<DivBackward0>) \n",
      "\n",
      "by may?\n",
      "\n",
      "Fir make at lest brit: me and at and this as as and are and leath nom of of stradlus have the\n",
      "the songain, it his ake shall, truch are the marty us sordons as are agay the day the comes, could\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.6415], grad_fn=<DivBackward0>) \n",
      "\n",
      "bell, Aute him! If antal shall sirsteise the unter.\n",
      "\n",
      "CLEONTES:\n",
      "Bedowle that the as bedness fuelo\n",
      "sich he lemar, I serdent, his wors his faster' tonce his he made, peatinst my ught give, But the namion \n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.8412], grad_fn=<DivBackward0>) \n",
      "\n",
      "ble grows\n",
      "And art ud with welle more is shear no coust, I hust sumbond the pildred a cander, as re?\n",
      "\n",
      "KING RICCIO:\n",
      "Firtom: as bedand,\n",
      "For of good, and as shash are not maden opry mare fire it upher, his\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.8542], grad_fn=<DivBackward0>) \n",
      "\n",
      "blessif cawnor, to host doot my not his flangent, they to the ary to mea! Kath you forth thy wound in gose to you hays and by to blong, dented are to and I day now,\n",
      "I sound, 'tleep, but than she rester\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.9393], grad_fn=<DivBackward0>) \n",
      "\n",
      "bring our great fives poor from a hose tasple the come not and not in withing her assion, may facose with to is with, sell.\n",
      "\n",
      "henet, and his pricied.\n",
      "\n",
      "RIMIO:\n",
      "Thithing a condounded offorth pert untood,\n",
      "I\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.6435], grad_fn=<DivBackward0>) \n",
      "\n",
      "but her Kath me dost of the prought goman her thuut not, speep our a make tist it it is you, streeps in onot ert stant foud,\n",
      "On and pyour you she some sperpuny\n",
      "Bronts again bade some the nome.\n",
      "\n",
      "KINGH:\n",
      "\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.7908], grad_fn=<DivBackward0>) \n",
      "\n",
      "bold hone will\n",
      "'d me May, heart:\n",
      "Head,\n",
      "I learring greeof Edunght be efreet, fatwer, this man puchide\n",
      "Wo knead, all tententle will to the couss in the wall he learan:\n",
      "Gombate of could of him, the way, c\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.8064], grad_fn=<DivBackward0>) \n",
      "\n",
      "bloud, you do heart our I denger:\n",
      "This part a tore,\n",
      "To seece.\n",
      "\n",
      "First of in then to she sount is save is this would bed on, as all your flem, heave it lord,\n",
      "To pould forth to hone soush of and seave rem\n",
      " ====================================================================================================\n",
      "\n",
      " tensor([1.8372], grad_fn=<DivBackward0>) \n",
      "\n",
      "bout, conferder, worlf sweem;\n",
      "I hand:\n",
      "If brother musband will this the peocle's of to be here speak to we had\n",
      "my city to both\n",
      "Hone come the couse thing the condan my lord.\n",
      "\n",
      "KANll non her cand her bean \n",
      " ====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_epochs):\n",
    "    inp, label = random_training_set()\n",
    "    hidden = model.init_hidden()\n",
    "    loss = torch.tensor([0]).type(torch.FloatTensor)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    for j in range(chunk_len-1):\n",
    "        x = inp[j]\n",
    "        y_ = label[j].unsqueeze(0).type(torch.LongTensor)\n",
    "        y, hidden = model(x, hidden)\n",
    "        loss += loss_func(y, y_)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i%100 == 0:\n",
    "        print(f'\\n {loss/chunk_len} \\n')\n",
    "        test()\n",
    "        print('\\n', '='*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
